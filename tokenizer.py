"""
This code was mainly generated by AI
and then manually edited to fit assignment specifications.
"""

import re

def tokenize(text, stopwords):
    # Lowercase
    text = text.lower()

    # Replace non-alphabetic characters with spaces
    text = re.sub(r"[^a-z0-9]+", " ", text)

    # Split into tokens
    tokens = text.split()

    # Remove stopwords and very short tokens
    return [t for t in tokens if t not in stopwords and len(t) > 1]